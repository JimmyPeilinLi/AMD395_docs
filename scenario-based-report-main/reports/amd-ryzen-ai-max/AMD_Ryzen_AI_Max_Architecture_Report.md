# AMD Ryzen AI Max 系列处理器深度技术调研报告

> 报告日期: 2026-01-07
>
> 本报告涵盖 AMD Ryzen AI Max+ 395 及 CES 2026 新发布产品的全面技术分析，包括 NPU/GPU 架构、开源情况、数据通路及 UMA 架构对比。

---

## 目录

1. [产品概述](#一产品概述)
2. [集成显卡与 NPU 功能分析](#二集成显卡与-npu-功能分析)
3. [开源情况调研](#三开源情况调研)
4. [NPU 体系结构详解](#四npu-体系结构详解)
5. [CPU/GPU/NPU 数据通路](#五cpugpunpu-数据通路)
6. [UMA vs 分离式架构对比](#六uma-vs-分离式架构对比)
7. [信息来源汇总](#七信息来源汇总)

---

## 一、产品概述

### 1.1 Ryzen AI Max+ 395 (CES 2025 发布)

这是 AMD 目前最强大的移动 x86 APU，代号 **Strix Halo**。

#### 核心规格

| 规格 | 详情 |
|------|------|
| **代号** | Strix Halo |
| **发布时间** | 2025 年 1 月 |
| **制程** | TSMC 4nm |
| **CPU 核心/线程** | 16 核 32 线程 (Zen 5) |
| **基础频率** | 2.0 GHz |
| **加速频率** | 5.1 GHz |
| **L3 缓存** | 64 MB（移动处理器中最大） |
| **TDP** | 55W 基础，最高 120W |

#### 集成显卡 (Radeon 8060S)

| 规格 | 详情 |
|------|------|
| **架构** | RDNA 3.5 |
| **计算单元** | 40 CU（2560 统一着色器） |
| **性能** | 60 TFLOPS |
| **可变显存** | 最高 96GB（通过 AMD Variable Graphics Memory） |
| **显示输出** | 支持四路 SUHD 4320p60 显示器 |
| **视频编解码** | AVC, HEVC, VP9, AV1 |

#### AI 能力

| 规格 | 详情 |
|------|------|
| **NPU** | 50 TOPS (XDNA 2 架构) |
| **总系统 AI TOPS** | 126 TOPS |

#### 内存支持

- 最高 128GB 统一内存
- 其中最高 112GB 可分配给 GPU
- 支持运行 700 亿参数大语言模型
- 256-bit LPDDR5X 接口
- 256 GB/s 理论带宽

#### 性能亮点

- **AI 性能**: 在 LM Studio 中比 RTX 4090 快 2.2 倍，功耗降低 87%
- **图形性能**: 3DMark Steel Nomad 是 Intel Core Ultra 9 288V 的 258%
- 全球首款支持 70B LLM 的 Windows 11 AI+ PC APU

---

### 1.2 CES 2026 新发布产品

#### Ryzen AI Max+ 392 & 388

AMD 在 CES 2026 扩展了 Strix Halo 产品线：

| 规格 | Max+ 395 | Max+ 392 | Max+ 388 |
|------|----------|----------|----------|
| **核心/线程** | 16C/32T | 12C/24T | 8C/16T |
| **架构** | Zen 5 | Zen 5 | Zen 5 |
| **加速频率** | 5.1 GHz | 5.0 GHz | 5.0 GHz |
| **L3 缓存** | 64 MB | 76 MB | - |
| **GPU** | Radeon 8060S (40 CU) | Radeon 8060S (40 CU) | Radeon 8060S (40 CU) |
| **GPU 性能** | 60 TFLOPS | 60 TFLOPS | 60 TFLOPS |
| **NPU** | 50 TOPS | 50 TOPS | 50 TOPS |
| **内存** | LPDDR5X 8533 MT/s | LPDDR5X 8533 MT/s | LPDDR5X 8533 MT/s |
| **最大内存** | 128GB | 128GB | 128GB |

**与普通 Max 版本的区别：** Max+ 392/388 保留完整的 40 CU GPU（60 TFLOPS），而普通 Max 390/385 只有 32 CU（48 TFLOPS）。

**适用场景：** Max+ 388 特别适合游戏掌机设备——保留完整 GPU 的同时减少 CPU 核心数，更易于平衡功耗、散热和电池续航。

**上市时间：** 2026 Q1，首批 OEM 包括 Acer 和 ASUS。

#### Ryzen AI 400 系列

| 规格 | 详情 |
|------|------|
| **架构** | Zen 5 |
| **最高配置** | 12 核 24 线程 |
| **加速频率** | 最高 5.2 GHz |
| **GPU** | Radeon 800M (16 CU RDNA 3.5) |
| **NPU** | 60 TOPS（旗舰型号）|

**重大突破：** 首次推出可插拔的桌面版 Zen 5 APU，不再局限于笔记本电脑。

**上市时间：** 笔记本 2026 Q1，桌面版 2026 Q2。

---

### 1.3 产品定位总结

| 产品 | 定位 | 特点 |
|------|------|------|
| **Ryzen AI Max+ 395** | 旗舰移动工作站 | 最强 CPU (16核) + GPU (40CU) |
| **Ryzen AI Max+ 392** | 高端创作者笔记本 | 12 核 + 完整 GPU |
| **Ryzen AI Max+ 388** | 游戏掌机/轻薄本 | 8 核 + 完整 GPU，功耗更优 |
| **Ryzen AI 400 系列** | 主流 AI PC | 60 TOPS NPU，首款桌面版 |

---

## 二、集成显卡与 NPU 功能分析

### 2.1 体系结构概览

```
┌─────────────────────────────────────────────────────────────────┐
│                     Strix Halo SoC (单芯片)                       │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐  │
│  │   Zen 5     │  │  RDNA 3.5   │  │      XDNA 2 NPU         │  │
│  │   CPU       │  │  iGPU       │  │   (空间数据流架构)        │  │
│  │  16C/32T    │  │  40 CU      │  │   32 AI Engine Tiles    │  │
│  │             │  │  60 TFLOPS  │  │   50 TOPS               │  │
│  └──────┬──────┘  └──────┬──────┘  └───────────┬─────────────┘  │
│         │                │                     │                 │
│         └────────────────┼─────────────────────┘                 │
│                          │                                       │
│              ┌───────────▼───────────┐                          │
│              │   Infinity Fabric     │                          │
│              │   + 32MB MALL Cache   │                          │
│              └───────────┬───────────┘                          │
│                          │                                       │
│              ┌───────────▼───────────┐                          │
│              │  256-bit LPDDR5X      │                          │
│              │  统一内存 (最高128GB)   │                          │
│              │  256 GB/s 带宽         │                          │
│              └───────────────────────┘                          │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 集成显卡 (Radeon 8060S) - RDNA 3.5

#### 硬件架构

| 参数 | 规格 |
|------|------|
| 计算单元 | 40 CU (2560 stream processors) |
| 架构 | RDNA 3.5 |
| FP32 算力 | 60 TFLOPS |
| 矩阵加速 | Wave Matrix Multiply Accumulate (WMMA) |
| 显存 | 统一内存，最高可分配 96GB |
| 带宽 | 实测 ~212 GB/s (理论 256 GB/s) |

#### AI 计算能力

**可以用于 AI 计算，且是 LLM 推理的主力：**

- **ROCm 支持**: ROCm 7.x 已支持 Strix Halo (gfx1151)，可运行 PyTorch、TensorFlow、llama.cpp
- **WMMA 指令**: 硬件级矩阵乘法加速，对 Transformer attention 计算友好
- **Flash Attention**: 通过 rocWMMA + AOTriton 支持，是目前最佳性能配置

**RDNA 3.5 AI 相关指令支持：**
- FP16/BF16 矩阵运算
- INT8 WMMA (相比 RDNA 3 提升)
- 注意：RDNA 4 才有 FP8/BF8 和 4:2 结构化稀疏支持

#### 适用场景

- **LLM 推理的 decode 阶段** (memory-bound，需要高带宽)
- 大批量推理任务
- 需要大显存的模型 (如 70B+ 参数 LLM)
- Stable Diffusion 等生成式 AI

### 2.3 NPU (XDNA 2) - 空间数据流架构

#### 硬件架构

源自 Xilinx Versal ACAP 技术，是完全不同于 GPU 的设计：

```
XDNA 2 Array (8 列 x 4 行 = 32 tiles)
┌────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐
│ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │
│ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │
├────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤
│ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │
│ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │
├────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤
│ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │
│ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │
├────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤
│ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │ AIE    │
│ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │
├────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤
│ Mem    │ Mem    │ Mem    │ Mem    │ Mem    │ Mem    │ Mem    │ Mem    │ ← L2 Memory Tiles
│ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │ Tile   │
└────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┘
          ↑↓ 可编程互连 (Packet/Circuit Switched)
```

**每个 AIE Tile 包含：**
- **VLIW + SIMD 向量处理器**: 128 FMA/cycle (BF16→FP32)
- **标量 RISC 处理器**: 控制流
- **专用程序存储器 + 数据存储器**
- **DMA 引擎**: 独立于计算核心，数据搬运与计算并行

#### 关键特性

| 特性 | 说明 |
|------|------|
| **无缓存设计** | 使用 SRAM buffer，延迟确定性高 |
| **可编程互连** | 运行时配置数据流路径，支持组播 |
| **显式数据移动** | 程序员/编译器控制所有数据传输 |
| **按列功耗门控** | 可单独关闭空闲列 |
| **并发模型** | 支持同时运行 8 个 AI 模型 |

#### 数据类型支持

| 格式 | 支持情况 |
|------|----------|
| INT8 | ✓ 主要优化目标 |
| Block BF16 | ✓ **首创** - FP16 精度 + INT8 效率 |
| INT4 | ✓ |
| FP16/BF16 | ✓ |

**Block BF16 是亮点**: 无需量化/重训练，即插即用

#### 软件栈

```
应用层
   │
   ▼
┌─────────────────────────────────────┐
│  ONNX Runtime + Vitis AI EP         │
│  (自动图分区: NPU 支持的 op → NPU,    │
│   不支持的 → CPU fallback)           │
└─────────────────────────────────────┘
   │
   ▼
┌─────────────────────────────────────┐
│  AMD Quark 量化器                    │
│  (PyTorch/ONNX → INT8/BF16)         │
└─────────────────────────────────────┘
   │
   ▼
┌─────────────────────────────────────┐
│  Vitis AI 编译器                     │
│  (ONNX → 微码可执行文件)              │
└─────────────────────────────────────┘
   │
   ▼
┌─────────────────────────────────────┐
│  XDNA Driver (Linux: amdxdna)       │
└─────────────────────────────────────┘
```

#### NPU 限制与约束

**算子支持**: 只支持 ONNX 算子子集，不支持的算子会 fallback 到 CPU

**已知支持**: Conv, MatMul, GEMM, Softmax, LayerNorm, GELU, PRelu, ReduceSum, DepthToSpace 等

**量化要求**: 输入模型必须是 INT8 或 BF16 量化格式

**编译开销**: 首次运行需编译，后续有缓存机制

### 2.4 GPU vs NPU 对比 (推理框架视角)

| 维度 | GPU (RDNA 3.5) | NPU (XDNA 2) |
|------|----------------|--------------|
| **峰值算力** | 60 TFLOPS (FP32) | 50 TOPS (INT8) |
| **内存访问** | 统一内存，~212 GB/s | 通过系统内存，带宽受限 |
| **延迟特性** | 较高启动延迟，高吞吐 | 低延迟 (<100ms)，确定性强 |
| **功耗** | 较高 | 极低 (比 CPU 高效 35x) |
| **编程模型** | ROCm/HIP (类 CUDA) | ONNX Runtime + Vitis AI EP |
| **灵活性** | 高，支持任意算子 | 受限于支持的 ONNX 算子 |
| **适用模型** | LLM, 扩散模型, 任意大模型 | CNN, Transformer (受限), 小模型 |
| **批处理** | 大批量高效 | 单/小批量更优 |

### 2.5 Disaggregated Inference (分离式推理)

AMD 推荐的 LLM 推理模式，利用 NPU + GPU 协同：

```
┌─────────────────────────────────────────────────────────────┐
│                    LLM 推理流程                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   输入 tokens                                               │
│       │                                                     │
│       ▼                                                     │
│   ┌───────────────────────────────────────┐                │
│   │     Prefill 阶段 (Compute-bound)      │                │
│   │     → 运行在 NPU                       │                │
│   │     → 高算力利用率                     │                │
│   │     → 低功耗                           │                │
│   └───────────────────┬───────────────────┘                │
│                       │ KV Cache                            │
│                       ▼                                     │
│   ┌───────────────────────────────────────┐                │
│   │     Decode 阶段 (Memory-bound)        │                │
│   │     → 运行在 GPU                       │                │
│   │     → 高带宽利用率 (212 GB/s)          │                │
│   │     → 大显存支持长上下文               │                │
│   └───────────────────────────────────────┘                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**实测效果**: AMD 官方数据显示，混合执行可以同时降低延迟和功耗

### 2.6 对推理框架开发者的建议

#### 如果你要支持 GPU 推理

```bash
# llama.cpp 最佳配置
cmake -B build -S . \
  -DGGML_HIP=ON \
  -DAMDGPU_TARGETS="gfx1151" \
  -DGGML_HIP_ROCWMMA_FATTN=ON

# 运行时必须参数
llama-server -fa 1 --no-mmap ...
```

**关键点**:
- 必须启用 Flash Attention (`-fa 1`)
- 必须禁用 mmap (`--no-mmap`)，否则统一内存会导致 kernel crash
- rocWMMA 对长上下文推理性能提升显著

#### 如果你要支持 NPU 推理

```python
import onnxruntime as ort

# 创建使用 Vitis AI EP 的 session
session = ort.InferenceSession(
    "model_quantized.onnx",
    providers=['VitisAIExecutionProvider', 'CPUExecutionProvider']
)
```

**关键点**:
- 模型必须量化为 INT8 或 BF16
- 使用 AMD Quark 进行量化
- 利用编译缓存机制减少冷启动时间
- 可用 `compile_report` 查看算子分配情况

#### 如果你要实现混合 NPU/GPU 推理

参考 AMD OGA (ONNX GenAI) hybrid model 实现：
- Prefill 子图 → NPU
- Decode 子图 → GPU
- KV Cache 需要在统一内存中共享

---

## 三、开源情况调研

### 3.1 总体开源程度对比

| 组件 | GPU (RDNA) | NPU (XDNA) |
|------|------------|------------|
| **内核驱动** | ✅ 完全开源 (amdgpu) | ✅ 开源 (amdxdna, Linux 6.14+) |
| **固件** | ⚠️ 闭源二进制 blob | ⚠️ 闭源二进制 blob |
| **编译器** | ✅ 开源 (LLVM/Clang) | ✅ 开源 (Peano/LLVM-AIE) |
| **运行时** | ✅ 开源 (ROCm/HIP) | ⚠️ 部分开源 |
| **AI 框架集成** | ✅ PyTorch/TF 原生支持 | ⚠️ 仅 ONNX Runtime |
| **自定义 kernel** | ✅ 完全支持 | ✅ 支持 (IRON/MLIR-AIE) |

### 3.2 GPU (RDNA 3.5) 开源情况

#### 完全开源的组件

```
┌─────────────────────────────────────────────────────────────┐
│                    GPU 软件栈                                │
├─────────────────────────────────────────────────────────────┤
│  应用层                                                      │
│    PyTorch, TensorFlow, JAX, llama.cpp ...                  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  ROCm Runtime (HIP)                         [开源]     │  │
│  │  github.com/ROCm/HIP                                  │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  ROCm Compiler (ROCmCC/hipcc)               [开源]     │  │
│  │  基于 LLVM/Clang                                       │  │
│  │  github.com/ROCm/llvm-project                         │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  数学库 (rocBLAS, hipBLASLt, MIOpen)        [开源]     │  │
│  │  github.com/ROCm/rocBLAS                              │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  内核驱动 (amdgpu)                          [开源]     │  │
│  │  Linux 内核主线                                        │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  GPU 固件                                   [闭源]     │  │
│  │  linux-firmware 包分发                                 │  │
│  └───────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

#### 开发者能做什么

**完全自定义 kernel 编程：**

```cpp
// HIP kernel 示例 - 与 CUDA 几乎相同
__global__ void vector_add(float* a, float* b, float* c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// 启动 kernel
hipLaunchKernelGGL(vector_add,
    dim3(blocks), dim3(threads), 0, 0,
    d_a, d_b, d_c, n);
```

**你可以：**
- 用 HIP/C++ 写任意 GPU kernel
- 用 HIPIFY 工具将 CUDA 代码转换为 HIP
- 直接使用 GCN/RDNA 汇编 (内联或独立)
- 使用 OpenCL、OpenMP offload
- 修改 ROCm 运行时和数学库源码

**关键仓库：**

| 仓库 | 用途 |
|------|------|
| [ROCm/HIP](https://github.com/ROCm/HIP) | HIP 运行时和 API |
| [ROCm/llvm-project](https://github.com/ROCm/llvm-project) | 编译器 |
| [ROCm/rocBLAS](https://github.com/ROCm/rocBLAS) | BLAS 库 |
| [ROCm/MIOpen](https://github.com/ROCm/MIOpen) | 深度学习原语库 |
| [ROCm/rocm-examples](https://github.com/ROCm/rocm-examples) | 示例代码 |

### 3.3 NPU (XDNA 2) 开源情况

#### 软件栈开源程度

```
┌─────────────────────────────────────────────────────────────┐
│                    NPU 软件栈                                │
├─────────────────────────────────────────────────────────────┤
│  方案 A: Vitis AI (官方生产环境)                              │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  ONNX Runtime + Vitis AI EP                [部分开源]  │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  AMD Quark 量化器                           [开源]     │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Vitis AI Compiler (v++)                   [需许可证]  │  │
│  │  NPU 指令编译器 - 非开源                               │  │
│  └───────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────┤
│  方案 B: MLIR-AIE/IRON (研究/底层开发)                       │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  IRON Python API                           [开源]     │  │
│  │  github.com/amd/IRON                                  │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  MLIR-AIE Dialect                          [开源]     │  │
│  │  github.com/Xilinx/mlir-aie                           │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Peano Compiler (LLVM-AIE)                 [开源]     │  │
│  │  AIE target for LLVM                                  │  │
│  └───────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────┤
│  共享层                                                      │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  XRT (Xilinx Runtime)                      [开源]     │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  amdxdna 内核驱动                          [开源]     │  │
│  │  Linux 6.14 主线                                       │  │
│  │  github.com/amd/xdna-driver                           │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                   │
│                          ▼                                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  NPU 固件                                  [闭源]     │  │
│  └───────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

#### 两条开发路径对比

| 特性 | Vitis AI (官方) | MLIR-AIE/IRON (开源) |
|------|-----------------|---------------------|
| **开源程度** | 编译器闭源 | 完全开源 |
| **易用性** | 高 (ONNX 模型直接部署) | 低 (需理解 AIE 架构) |
| **灵活性** | 仅支持 ONNX 算子子集 | 可写任意 AIE kernel |
| **文档** | 完善 | 较少，需看源码 |
| **生产就绪** | 是 | 实验性质 |
| **适用场景** | 标准 ML 推理 | 研究、自定义算子、DSP |

#### 使用 IRON 自定义 NPU kernel

IRON 允许你直接编写在 AIE tile 上运行的代码：

```python
# IRON Python API 示例
from iron import *

# 定义数据流
@kernel
def my_custom_kernel(in_buffer, out_buffer):
    # AIE 向量化代码
    for i in range(16):
        out_buffer[i] = in_buffer[i] * 2

# 定义 tile 映射
with device("npu"):
    tile = aie_tile(0, 2)  # 列 0, 行 2
    mem = aie_mem(tile)

    # 配置数据移动
    dma_in = dma_channel(tile, direction="in")
    dma_out = dma_channel(tile, direction="out")

    # 部署 kernel
    tile.program(my_custom_kernel)
```

**C++ AIE kernel (Peano 编译)：**

```cpp
// AIE kernel 使用 AIE API
#include <aie_api/aie.hpp>

void vector_mul(int32_t* __restrict in,
                int32_t* __restrict out,
                int32_t scale) {
    // 向量化操作
    aie::vector<int32_t, 16> vec = aie::load_v<16>(in);
    aie::vector<int32_t, 16> result = aie::mul(vec, scale);
    aie::store_v(out, result);
}
```

#### Riallto 学习平台

AMD 提供了 [Riallto](https://riallto.ai/) 作为 NPU 探索框架：

- Jupyter notebook 环境
- 可视化 AIE 架构
- 示例 kernel 和数据流编程
- 适合学习 NPU 编程模型

### 3.4 NVIDIA CUDA vs AMD ROCm vs AMD NPU 对比

#### 软件栈开源程度对比

```
                    NVIDIA CUDA              AMD GPU (ROCm)           AMD NPU (XDNA)
                    ───────────              ──────────────           ──────────────
应用框架            PyTorch/TF [开源]        PyTorch/TF [开源]        ONNX Runtime [开源]
                         │                        │                        │
                         ▼                        ▼                        ▼
数学库              cuDNN/cuBLAS             rocBLAS/MIOpen           Vitis AI Libs
                    [闭源]                   [开源]                   [部分开源]
                         │                        │                        │
                         ▼                        ▼                        ▼
编译器              nvcc (NVVM)              ROCmCC (LLVM)            Vitis AI / Peano
                    [闭源]                   [开源]                   [闭源] / [开源]
                         │                        │                        │
                         ▼                        ▼                        ▼
运行时              CUDA Runtime             HIP Runtime              XRT Runtime
                    [闭源]                   [开源]                   [开源]
                         │                        │                        │
                         ▼                        ▼                        ▼
内核驱动            nvidia.ko                amdgpu                   amdxdna
                    [闭源]                   [开源]                   [开源]
                         │                        │                        │
                         ▼                        ▼                        ▼
固件                [闭源]                   [闭源]                   [闭源]
```

#### 详细对比表

| 组件 | NVIDIA CUDA | AMD GPU (ROCm) | AMD NPU (XDNA) |
|------|-------------|----------------|----------------|
| **内核驱动** | ❌ 闭源 (nvidia.ko) | ✅ 开源 (amdgpu, 主线) | ✅ 开源 (amdxdna, 6.14+) |
| **用户态驱动** | ❌ 闭源 | ✅ 开源 | ✅ 开源 (XRT) |
| **编译器** | ❌ 闭源 (nvcc/NVVM) | ✅ 开源 (LLVM fork) | ⚠️ 两条路: 闭源(Vitis)/开源(Peano) |
| **运行时** | ❌ 闭源 (libcuda) | ✅ 开源 (HIP) | ⚠️ 部分开源 |
| **数学库** | ❌ 闭源 (cuBLAS/cuDNN) | ✅ 开源 (rocBLAS/MIOpen) | ⚠️ 部分开源 |
| **固件** | ❌ 闭源 blob | ❌ 闭源 blob | ❌ 闭源 blob |
| **ISA 文档** | ⚠️ 有限公开 (PTX) | ⚠️ 部分公开 (RDNA 白皮书) | ⚠️ 有限 (需逆向/MLIR) |

#### 开发者能力对比

| 能力 | NVIDIA CUDA | AMD GPU | AMD NPU |
|------|-------------|---------|---------|
| **写自定义 kernel** | ✅ CUDA C/C++ | ✅ HIP C/C++ | ✅ IRON/C++ (开源路径) |
| **修改编译器** | ❌ 不可能 | ✅ 可以 fork LLVM | ✅ 可以 fork Peano |
| **修改运行时** | ❌ 不可能 | ✅ 可以修改 HIP | ✅ 可以修改 XRT |
| **修改数学库** | ❌ 不可能 | ✅ 可以修改 rocBLAS | ⚠️ 有限 |
| **内核级调试** | ⚠️ 工具有限 | ✅ 源码可查 | ✅ 源码可查 |
| **添加新硬件支持** | ❌ 不可能 | ✅ 理论上可以 | ✅ 理论上可以 |

#### 生态成熟度对比

| 维度 | NVIDIA CUDA | AMD ROCm | AMD NPU |
|------|-------------|----------|---------|
| **历史** | 2007 (~18年) | 2016 (~9年) | 2024 (~1年) |
| **开发者数量** | 数百万 | 数万 | 数千 |
| **框架支持** | 所有主流框架原生支持 | PyTorch/TF/JAX 支持 | 仅 ONNX Runtime |
| **文档质量** | 优秀 | 良好 | 一般 |
| **社区活跃度** | 极高 | 中等 | 低 |
| **企业支持** | 极强 | 增长中 | 早期 |

#### 代码移植难度

```
CUDA 代码 ──────────────────────────────────────────────────────────────┐
    │                                                                   │
    │  HIPIFY (自动转换工具)                                             │
    │  90%+ 代码可直接转换                                               │
    ▼                                                                   │
AMD HIP 代码 ◄──────────────────────────────────────────────────────────┘
    │
    │  无直接路径
    │  需要完全重写
    ▼
AMD NPU 代码 (IRON/MLIR-AIE)
```

**CUDA → HIP 示例：**

```cpp
// CUDA 原始代码
cudaMalloc(&d_ptr, size);
cudaMemcpy(d_ptr, h_ptr, size, cudaMemcpyHostToDevice);
kernel<<<blocks, threads>>>(d_ptr);
cudaDeviceSynchronize();

// HIPIFY 转换后 (几乎一一对应)
hipMalloc(&d_ptr, size);
hipMemcpy(d_ptr, h_ptr, size, hipMemcpyHostToDevice);
hipLaunchKernelGGL(kernel, blocks, threads, 0, 0, d_ptr);
hipDeviceSynchronize();
```

**ZLUDA 项目：** AMD 资助了一个二进制兼容层，可以让很多 CUDA 程序无需修改直接运行在 ROCm 上。

#### 开源程度总结

```
完全闭源 ◄─────────────────────────────────────────────► 完全开源

NVIDIA CUDA        AMD NPU (Vitis)    AMD NPU (IRON)    AMD ROCm
    │                    │                  │               │
    ▼                    ▼                  ▼               ▼
████████████░░░░   ██████████░░░░░░   ███░░░░░░░░░░░   ██░░░░░░░░░░░░░
   ~15%                ~40%               ~70%             ~85%
(仅 CUDA 代码       (驱动开源,         (全栈开源,        (除固件外
 可用, 其他         编译器闭源)        但不成熟)         全部开源)
 全闭源)
```

### 3.5 对推理框架开发者的实际建议

#### 如果你要支持 GPU 推理

**开源程度：优秀，可深度定制**

```bash
# 完整开源工具链
git clone https://github.com/ROCm/llvm-project  # 编译器
git clone https://github.com/ROCm/HIP           # 运行时
git clone https://github.com/ROCm/rocBLAS       # 数学库
```

你可以：
- 添加自定义 GEMM kernel
- 修改 Flash Attention 实现
- 实现新的融合算子
- 完全控制内存管理

#### 如果你要支持 NPU 推理

**选项 1: 使用 Vitis AI (推荐生产环境)**
- 优点：稳定、有官方支持
- 缺点：编译器闭源，只能用支持的 ONNX 算子
- 适合：标准 CNN/Transformer 模型部署

**选项 2: 使用 MLIR-AIE/IRON (研究/自定义)**
- 优点：完全开源，可写任意 kernel
- 缺点：学习曲线陡峭，文档较少
- 适合：研究、自定义算子、非标准工作负载

```bash
# 开源 NPU 工具链
git clone https://github.com/Xilinx/mlir-aie    # MLIR dialect
git clone https://github.com/amd/IRON           # Python API
git clone https://github.com/amd/xdna-driver    # 内核驱动
```

#### 关键限制

| 限制 | GPU | NPU |
|------|-----|-----|
| **固件** | 闭源，无法修改 | 闭源，无法修改 |
| **ISA 文档** | 部分公开 (RDNA 白皮书) | 有限 (需要通过 MLIR-AIE 推断) |
| **硬件调试** | 有 rocprof 等工具 | 工具有限 |

---

## 四、NPU 体系结构详解

### 4.1 三种架构范式对比

```
┌────────────────────────────────────────────────────────────────────────────┐
│                        计算架构范式对比                                      │
├────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│  CPU: 时间复用 (Temporal)          "一个强核，串行执行复杂指令流"            │
│  ════════════════════════                                                  │
│  指令1 → 指令2 → 指令3 → 指令4 → ...   (深流水线，乱序执行)                 │
│                                                                            │
│  GPU: 数据并行 (SIMT)              "海量弱核，并行执行相同指令"              │
│  ════════════════════════                                                  │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐                                          │
│  │同指令│ │同指令│ │同指令│ │同指令│   (数千线程同时执行)                    │
│  │数据1│ │数据2│ │数据3│ │数据4│                                          │
│  └─────┘ └─────┘ └─────┘ └─────┘                                          │
│                                                                            │
│  NPU: 空间数据流 (Spatial Dataflow) "数据在计算单元间流动"                  │
│  ══════════════════════════════════                                        │
│  输入 → [Tile A] → [Tile B] → [Tile C] → [Tile D] → 输出                   │
│           ↓          ↓          ↓          ↓                               │
│        [Tile E] → [Tile F] → [Tile G] → [Tile H]                          │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 CPU 流水线 vs GPU SM vs NPU AIE Tile

| 特性 | CPU Core | GPU SM | NPU AIE Tile |
|------|----------|--------|--------------|
| **设计目标** | 低延迟，复杂控制流 | 高吞吐，数据并行 | 高效率，数据流 |
| **核心数量** | 4-32 | 数千 (CUDA cores) | 20-32 tiles |
| **单核复杂度** | 极高 | 低 | 中等 |
| **流水线** | 深 (15-20级)，乱序 | 浅，顺序 | VLIW (7-way) |
| **SIMD 宽度** | 128-512 bit (AVX) | 32 threads/warp | 256-1024 bit |
| **缓存** | 多级 (L1/L2/L3) | L1/L2 + 共享内存 | 无缓存，显式 SRAM |
| **内存访问** | 隐式 (硬件管理) | 半显式 | 完全显式 (DMA) |
| **调度** | 硬件动态调度 | 硬件 warp 调度 | 软件静态调度 |

### 4.3 XDNA AIE Tile 微架构详解

#### 单个 AIE Tile 结构

```
┌─────────────────────────────────────────────────────────────────┐
│                      AIE Tile (单个计算单元)                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │                    程序存储器 (16 KB)                      │  │
│  │                    存储 VLIW 指令                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │              VLIW 指令解码器 (7-way 并行)                  │  │
│  │  ┌────────┬────────┬────────┬────────┬────────┬────────┐ │  │
│  │  │ Scalar │ Move 1 │ Move 2 │ Load 1 │ Load 2 │ Store  │ │  │
│  │  │  Op    │        │        │ (256b) │ (256b) │ (256b) │ │  │
│  │  └────────┴────────┴────────┴────────┴────────┴────────┘ │  │
│  │                           │                               │  │
│  │                    ┌──────┴──────┐                       │  │
│  │                    │  Vector Op  │  (可与上述并行)         │  │
│  │                    │  (SIMD)     │                       │  │
│  │                    └─────────────┘                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│         ┌────────────────────┼────────────────────┐            │
│         ▼                    ▼                    ▼            │
│  ┌────────────┐      ┌────────────────┐    ┌──────────┐       │
│  │ 标量寄存器  │      │   向量寄存器    │    │ 累加寄存器│       │
│  │   (32b)    │      │ V: 128b        │    │  (256b)  │       │
│  │            │      │ W: 256b        │    │ 4x 并行  │       │
│  │            │      │ X: 512b        │    │ MAC 输出 │       │
│  │            │      │ Y: 1024b       │    │          │       │
│  └────────────┘      └────────────────┘    └──────────┘       │
│         │                    │                    │            │
│         └────────────────────┼────────────────────┘            │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │              数据存储器 (64 KB SRAM)                       │  │
│  │              可与邻居 tile 共享                             │  │
│  └──────────────────────────────────────────────────────────┘  │
│         │                    │                    │            │
│         ▼                    ▼                    ▼            │
│  ┌──────────┐         ┌──────────┐         ┌──────────┐       │
│  │ DMA 引擎 │         │ 级联流   │         │ AXI-Stream│       │
│  │ (S2MM/   │         │ (Cascade)│         │  Switch   │       │
│  │  MM2S)   │         │ 384b/cyc │         │ (32b)     │       │
│  └──────────┘         └──────────┘         └──────────┘       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### VLIW 指令格式

每个周期可以同时发射 **7 个操作**：

```
┌─────────────────────────────────────────────────────────────────┐
│                    单条 VLIW 指令 (每周期)                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Slot 0: Scalar Op     ─  标量整数/控制操作                      │
│  Slot 1: Move 1        ─  寄存器间数据移动                       │
│  Slot 2: Move 2        ─  寄存器间数据移动                       │
│  Slot 3: Vector Load 1 ─  256-bit 从内存加载到向量寄存器         │
│  Slot 4: Vector Load 2 ─  256-bit 从内存加载到向量寄存器         │
│  Slot 5: Vector Store  ─  256-bit 从向量寄存器写入内存           │
│  Slot 6: Vector MAC    ─  SIMD 乘加运算                         │
│                                                                 │
│  示例: 一条指令同时完成:                                         │
│  - 加载 A[i:i+8] 到 V0                                          │
│  - 加载 B[i:i+8] 到 V1                                          │
│  - 计算 V2 = V0 * V1 + V3 (8 个 FP32 MAC)                       │
│  - 存储上一轮结果到 C[i-8:i]                                     │
│  - 更新循环计数器                                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 向量单元计算能力

```
每个 AIE Tile 向量单元:
┌─────────────────────────────────────────────────────────────┐
│  数据类型          │  每周期 MAC 数    │  @ 1GHz 算力        │
├─────────────────────────────────────────────────────────────┤
│  INT8 × INT8       │  256 MACs        │  512 GOPS          │
│  INT16 × INT16     │  64 MACs         │  128 GOPS          │
│  BF16 × BF16→FP32  │  128 MACs        │  256 GFLOPS        │
│  FP32 × FP32       │  16 MACs         │  32 GFLOPS         │
└─────────────────────────────────────────────────────────────┘

XDNA 2 (32 tiles @ ~1.3 GHz):
- INT8: 32 × 512 × 1.3 = ~21 TOPS (理论)
- 实测 50 TOPS (包含稀疏优化等)
```

### 4.4 空间数据流 vs GPU SIMT 执行模型

#### GPU 执行模型 (以 NVIDIA 为例)

```
┌─────────────────────────────────────────────────────────────────┐
│                    GPU SM 执行模型                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Grid (网格)                                                    │
│  ├── Block 0 ──► SM 0                                          │
│  ├── Block 1 ──► SM 1     ← 块到 SM 的调度由硬件完成             │
│  ├── Block 2 ──► SM 2                                          │
│  └── ...                                                        │
│                                                                 │
│  SM 内部:                                                       │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Warp 调度器 (硬件)                                     │    │
│  │  ┌──────────────────────────────────────────────────┐  │    │
│  │  │  Warp 0 (32 threads): 指令 PC=100                 │  │    │
│  │  │  Warp 1 (32 threads): 指令 PC=104  ← 等待内存     │  │    │
│  │  │  Warp 2 (32 threads): 指令 PC=108                 │  │    │
│  │  │  Warp 3 (32 threads): 指令 PC=100                 │  │    │
│  │  └──────────────────────────────────────────────────┘  │    │
│  │                         │                              │    │
│  │                         ▼                              │    │
│  │  ┌──────────────────────────────────────────────────┐  │    │
│  │  │  SIMT 执行单元 (所有活跃线程执行相同指令)          │  │    │
│  │  │  if (threadIdx.x < N) { ... }  ← 分支发散问题     │  │    │
│  │  └──────────────────────────────────────────────────┘  │    │
│  └────────────────────────────────────────────────────────┘    │
│                                                                 │
│  内存访问: 合并访问 (Coalesced) → 高效                          │
│           非合并访问 → 性能下降                                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### NPU 空间数据流执行模型

```
┌─────────────────────────────────────────────────────────────────┐
│                    NPU 空间数据流执行模型                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  编译时: 将计算图映射到物理 tile 阵列                            │
│                                                                 │
│  运行时: 数据在 tile 间流动，每个 tile 执行自己的程序             │
│                                                                 │
│  示例: 3x3 卷积 + ReLU + Pooling                                │
│                                                                 │
│  输入数据流                                                      │
│      │                                                          │
│      ▼                                                          │
│  ┌────────┐    ┌────────┐    ┌────────┐                        │
│  │ Tile 0 │───►│ Tile 1 │───►│ Tile 2 │                        │
│  │ Conv   │    │ Conv   │    │ Conv   │  ← 并行处理不同通道      │
│  │ Row 0  │    │ Row 1  │    │ Row 2  │                        │
│  └───┬────┘    └───┬────┘    └───┬────┘                        │
│      │             │             │                              │
│      ▼             ▼             ▼                              │
│  ┌────────┐    ┌────────┐    ┌────────┐                        │
│  │ Tile 4 │◄───│ Tile 5 │◄───│ Tile 6 │                        │
│  │ Accum  │    │ Accum  │    │ Accum  │  ← 累加部分和           │
│  │ +ReLU  │    │ +ReLU  │    │ +ReLU  │                        │
│  └───┬────┘    └───┬────┘    └───┬────┘                        │
│      │             │             │                              │
│      └─────────────┼─────────────┘                              │
│                    ▼                                            │
│               ┌────────┐                                        │
│               │ Tile 8 │                                        │
│               │Pooling │  ← 汇聚结果                            │
│               └───┬────┘                                        │
│                   │                                             │
│                   ▼                                             │
│               输出数据                                           │
│                                                                 │
│  关键特点:                                                       │
│  - 无中央调度器，每个 tile 独立执行                              │
│  - 数据通过 DMA + stream 在 tile 间传输                         │
│  - 流水线式处理，tile 间可重叠执行                               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 4.5 内存与数据移动模型对比

#### 三种架构的内存层次

```
CPU:                        GPU:                        NPU:
════                        ════                        ════

寄存器 (~1KB)              寄存器 (256KB/SM)           寄存器 (~4KB/tile)
    ↓                          ↓                           ↓
L1 Cache (32-64KB)         L1 Cache (128KB)           本地 SRAM (64KB)
    ↓                          ↓                           ↓
L2 Cache (256KB-1MB)       L2 Cache (4-6MB)           邻居 SRAM (共享)
    ↓                          ↓                           ↓
L3 Cache (8-64MB)          ────────────                Memory Tile (L2)
    ↓                          ↓                           ↓
主存 (DDR/LPDDR)           显存 (HBM/GDDR)            统一内存 (LPDDR5X)

访问延迟:                   访问延迟:                   访问延迟:
L1: ~4 cycles              L1: ~30 cycles             SRAM: ~1 cycle
L2: ~12 cycles             L2: ~200 cycles            Neighbor: ~几 cycles
L3: ~40 cycles             HBM: ~400 cycles           DDR: ~100+ cycles
DDR: ~100+ cycles

关键区别:
- CPU/GPU: 硬件自动管理缓存 (隐式)
- NPU: 软件显式管理所有数据移动 (无缓存)
```

#### NPU 显式数据移动

```cpp
// GPU 隐式内存访问 (硬件管理缓存)
__global__ void kernel(float* A, float* B, float* C) {
    int i = threadIdx.x;
    C[i] = A[i] + B[i];  // 硬件自动处理缓存、预取
}

// NPU 显式数据移动 (软件控制一切)
void npu_kernel() {
    // 1. 显式配置 DMA 传输
    dma_config(channel_in, src=DDR_ADDR, dst=LOCAL_SRAM, size=1024);
    dma_start(channel_in);
    dma_wait(channel_in);

    // 2. 计算 (数据已在本地 SRAM)
    for (int i = 0; i < 256; i += 8) {
        vec_a = load_vector(local_sram + i);
        vec_b = load_vector(local_sram + 256 + i);
        vec_c = vec_mac(vec_a, vec_b, vec_acc);
        store_vector(local_sram + 512 + i, vec_c);
    }

    // 3. 显式配置输出 DMA
    dma_config(channel_out, src=LOCAL_SRAM+512, dst=DDR_ADDR_OUT, size=1024);
    dma_start(channel_out);
    // 不等待，流水线下一批数据
}
```

### 4.6 互连网络对比

```
┌─────────────────────────────────────────────────────────────────┐
│                       互连架构对比                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  CPU: 总线/环形互连                                              │
│  ═══════════════════                                            │
│  Core 0 ←──┬──→ Core 1                                         │
│            │                                                    │
│       Ring Bus / Mesh                                           │
│            │                                                    │
│  Core 2 ←──┴──→ Core 3                                         │
│                                                                 │
│  特点: 一致性协议 (MESI/MOESI)，硬件保证缓存一致性               │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  GPU: 层次化互连                                                 │
│  ═══════════════════                                            │
│  SM 0 ──┬── SM 1 ──┬── SM 2 ──┬── SM 3                         │
│         │          │          │                                 │
│         └────┬─────┴────┬─────┘                                │
│              │   GPC    │                                       │
│              └────┬─────┘                                       │
│                   │                                             │
│              Crossbar → L2 Cache → Memory Controller            │
│                                                                 │
│  特点: SM 间无直接通信，通过共享内存/L2 交换数据                 │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  NPU: 2D Mesh + 可编程路由                                       │
│  ═══════════════════════════                                    │
│                                                                 │
│     Col 0    Col 1    Col 2    Col 3    Col 4                  │
│    ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐                │
│ R3 │ AIE │══│ AIE │══│ AIE │══│ AIE │══│ AIE │ ← Cascade 流    │
│    └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘                │
│       ║        ║        ║        ║        ║                    │
│    ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐                │
│ R2 │ AIE │══│ AIE │══│ AIE │══│ AIE │══│ AIE │                │
│    └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘                │
│       ║        ║        ║        ║        ║     ↑              │
│    ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  │ 内存共享    │
│ R1 │ AIE │══│ AIE │══│ AIE │══│ AIE │══│ AIE │  │              │
│    └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  ↓              │
│       ║        ║        ║        ║        ║                    │
│    ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐  ┌──╫──┐                │
│ R0 │ AIE │══│ AIE │══│ AIE │══│ AIE │══│ AIE │                │
│    └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘                │
│       ║        ║        ║        ║        ║                    │
│    ┌──╨──┐  ┌──╨──┐  ┌──╨──┐  ┌──╨──┐  ┌──╨──┐                │
│    │ Mem │  │ Mem │  │ Mem │  │ Mem │  │ Mem │ ← Memory Tiles │
│    │Tile │  │Tile │  │Tile │  │Tile │  │Tile │                │
│    └─────┘  └─────┘  └─────┘  └─────┘  └─────┘                │
│                                                                 │
│  互连类型:                                                       │
│  ═ : AXI-Stream (32b, 可编程路由, 电路/包交换)                  │
│  ║ : 内存接口 (256b load/store)                                 │
│  → : Cascade 流 (384b/cycle, 固定方向)                          │
│                                                                 │
│  特点:                                                           │
│  - 软件在编译时配置路由                                          │
│  - 支持组播 (一对多)                                             │
│  - 无一致性协议开销                                              │
│  - DMA 与计算完全并行                                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 4.7 为什么 NPU 对 AI 推理高效？

| 因素 | CPU 问题 | GPU 问题 | NPU 优势 |
|------|---------|---------|----------|
| **内存带宽** | 低 (~100 GB/s) | 高但功耗大 | 本地 SRAM 避免 DDR 访问 |
| **控制开销** | 分支预测、乱序执行 | Warp 调度器 | 静态调度，无运行时开销 |
| **数据重用** | 缓存不可控 | 需要手动 tile | 显式控制，最大化重用 |
| **功耗** | 复杂流水线耗电 | 大量线程上下文 | 简单核，显式控制 |
| **延迟确定性** | 缓存 miss 不确定 | warp 调度不确定 | 确定性延迟 (无缓存) |

### 4.8 适用场景总结

```
┌─────────────────────────────────────────────────────────────────┐
│                      最佳适用场景                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  CPU:  复杂控制流、低延迟单任务、通用计算                        │
│        └─ 操作系统、数据库、编译器、游戏逻辑                     │
│                                                                 │
│  GPU:  大规模数据并行、训练、批量推理                            │
│        └─ LLM 训练、大 batch 推理、科学计算                      │
│                                                                 │
│  NPU:  固定拓扑 AI 模型、低功耗推理、实时处理                    │
│        └─ 端侧 CNN/Transformer、视频分析、语音识别               │
│                                                                 │
│  混合: LLM 推理                                                  │
│        └─ Prefill (compute-bound) → NPU                         │
│        └─ Decode (memory-bound) → GPU                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 五、CPU/GPU/NPU 数据通路

### 5.1 Strix Halo 芯片级架构

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        Strix Halo SoC 芯片布局                               │
│                        (InFO_oS 封装, 两个 die)                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────┐  ┌─────────────────────────────────┐  │
│  │         Compute Die             │  │           I/O Die               │  │
│  │  ┌───────────┬───────────┐      │  │                                 │  │
│  │  │   CCX 0   │   CCX 1   │      │  │  ┌─────────────────────────┐   │  │
│  │  │ 8x Zen 5  │ 8x Zen 5  │      │  │  │   Memory Controllers    │   │  │
│  │  │  32MB L3  │  32MB L3  │      │  │  │   256-bit LPDDR5X       │   │  │
│  │  └─────┬─────┴─────┬─────┘      │  │  │   8 channels            │   │  │
│  │        │           │            │  │  └───────────┬─────────────┘   │  │
│  │        │  Infinity │            │  │              │                 │  │
│  │        │  Fabric   │            │  │  ┌───────────┴─────────────┐   │  │
│  │        │    ↓↑     │            │  │  │      32MB MALL          │   │  │
│  │  ┌─────┴───────────┴─────┐      │  │  │   (Infinity Cache)      │   │  │
│  │  │                       │      │  │  └───────────┬─────────────┘   │  │
│  │  │    RDNA 3.5 GPU       │      │  │              │                 │  │
│  │  │      40 CU            │      │  │              │                 │  │
│  │  │   8x IF Endpoints     │      │  │  ┌───────────┴─────────────┐   │  │
│  │  │                       │      │  │  │    Infinity Fabric      │   │  │
│  │  └───────────┬───────────┘      │  │  │      Crossbar           │   │  │
│  │              │                  │◄═══►│                         │   │  │
│  │  ┌───────────┴───────────┐      │Die │  └───────────┬─────────────┘   │  │
│  │  │    XDNA 2 NPU         │      │Link│              │                 │  │
│  │  │   32 AIE Tiles        │      │    │  ┌───────────┴─────────────┐   │  │
│  │  │   50 TOPS             │      │  │  │   PCIe / USB / etc      │   │  │
│  │  └───────────────────────┘      │  │  └─────────────────────────┘   │  │
│  │                                 │  │                                 │  │
│  └─────────────────────────────────┘  └─────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 Infinity Fabric 互连拓扑

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     Infinity Fabric 互连详情                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                           ┌─────────────────┐                               │
│                           │  LPDDR5X        │                               │
│                           │  256 GB/s       │                               │
│                           │  (8 channels)   │                               │
│                           └────────┬────────┘                               │
│                                    │                                        │
│                           ┌────────▼────────┐                               │
│                           │   32MB MALL     │                               │
│                           │ (Infinity Cache)│                               │
│                           │  共享 Last Level│                               │
│                           └────────┬────────┘                               │
│                                    │                                        │
│              ┌─────────────────────┼─────────────────────┐                  │
│              │                     │                     │                  │
│              │         Infinity Fabric Crossbar          │                  │
│              │            (片上互连网络)                   │                  │
│              │                     │                     │                  │
│    ┌─────────┴──────┐    ┌────────┴────────┐   ┌───────┴────────┐          │
│    │                │    │                 │   │                │          │
│    ▼                ▼    ▼                 ▼   ▼                ▼          │
│ ┌──────┐        ┌──────┐ ┌───────────────────┐ ┌──────────────────┐        │
│ │CCX 0 │        │CCX 1 │ │       GPU         │ │       NPU        │        │
│ │ IF   │        │ IF   │ │  8x IF Endpoints  │ │   IF Endpoint    │        │
│ │ EP   │        │ EP   │ │  64B/cyc each     │ │   + PCIe 逻辑    │        │
│ │      │        │      │ │  = 512B/cyc total │ │                  │        │
│ │ 32B/ │        │ 32B/ │ │                   │ │                  │        │
│ │ cyc  │        │ cyc  │ │  @ 2GHz FCLK:     │ │  专用高带宽      │        │
│ │      │        │      │ │  ~1 TB/s 理论     │ │  SoC Fabric      │        │
│ └──────┘        └──────┘ └───────────────────┘ └──────────────────┘        │
│                                                                             │
│ 带宽分配:                                                                    │
│ - GPU: 高优先级，8个端点，最大带宽                                            │
│ - CPU: 低延迟优先，带宽次之                                                  │
│ - NPU: 专用 fabric，按需带宽                                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.3 统一内存架构详解

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        统一内存地址空间                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  物理内存: 128 GB LPDDR5X                                                   │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                                                                     │   │
│  │  ┌─────────────────────┐  ┌─────────────────────────────────────┐  │   │
│  │  │     CPU 专用区      │  │           GPU 专用区 (VRAM)          │  │   │
│  │  │      32 GB          │  │             96 GB                   │  │   │
│  │  │                     │  │                                     │  │   │
│  │  │  - 内核/用户空间    │  │  - 纹理、帧缓冲                      │  │   │
│  │  │  - 应用程序堆栈     │  │  - LLM 权重                         │  │   │
│  │  │                     │  │  - KV Cache                         │  │   │
│  │  └─────────────────────┘  └─────────────────────────────────────┘  │   │
│  │                                                                     │   │
│  │  访问权限:                                                          │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  处理器  │  CPU 区域  │  GPU 区域 (读)  │  GPU 区域 (写)     │ │   │
│  │  ├───────────────────────────────────────────────────────────────┤ │   │
│  │  │   CPU    │    R/W     │      R          │       ✗           │ │   │
│  │  │   GPU    │    R       │      R/W        │      R/W          │ │   │
│  │  │   NPU    │    R       │      R          │       ✗           │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │                                                                     │   │
│  │  关键特点:                                                          │   │
│  │  - GPU 可读取整个 128GB (零拷贝访问 CPU 数据)                        │   │
│  │  - GPU 只能写入自己的 96GB 专用区                                   │   │
│  │  - NPU 通过 DMA 访问任意物理地址                                    │   │
│  │  - 消除了 CPU↔GPU 显式数据拷贝                                      │   │
│  │                                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.4 NPU 数据通路详解

#### NPU 在系统中的位置

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      NPU 系统接口                                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  从 CPU 视角: NPU 表现为一个 PCIe 设备                                       │
│                                                                             │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                         Linux 内核                                    │  │
│  │  ┌────────────────┐                                                  │  │
│  │  │  用户空间应用   │                                                  │  │
│  │  │  (ONNX Runtime) │                                                  │  │
│  │  └───────┬────────┘                                                  │  │
│  │          │ ioctl                                                      │  │
│  │          ▼                                                            │  │
│  │  ┌────────────────┐     ┌─────────────────┐                          │  │
│  │  │  XRT SHIM      │────►│  amdxdna.ko     │                          │  │
│  │  │  (用户态库)     │     │  (内核驱动)      │                          │  │
│  │  └────────────────┘     └────────┬────────┘                          │  │
│  │                                  │                                    │  │
│  └──────────────────────────────────┼────────────────────────────────────┘  │
│                                     │                                       │
│                                     ▼                                       │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                        NPU 硬件接口                                   │  │
│  │                                                                      │  │
│  │    ┌─────────────────────────────────────────────────────────────┐  │  │
│  │    │                    PCIe BARs                                │  │  │
│  │    │  - BAR 0: 寄存器空间 (配置、状态)                            │  │  │
│  │    │  - BAR 2: 命令队列                                          │  │  │
│  │    │  - BAR 4: 数据缓冲区映射                                    │  │  │
│  │    │  - MSI-X: 中断向量                                          │  │  │
│  │    └─────────────────────────────────────────────────────────────┘  │  │
│  │                              │                                      │  │
│  │                              ▼                                      │  │
│  │    ┌─────────────────────────────────────────────────────────────┐  │  │
│  │    │              专用高带宽 SoC Fabric                           │  │  │
│  │    │           (不走标准 PCIe 物理层)                             │  │  │
│  │    │              直接连接统一内存                                 │  │  │
│  │    └─────────────────────────────────────────────────────────────┘  │  │
│  │                                                                      │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### NPU 内部数据通路

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      NPU (XDNA 2) 内部数据流                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                         主机内存 (LPDDR5X)                                   │
│                               │                                             │
│                      ┌────────┴────────┐                                    │
│                      │    SoC Fabric   │                                    │
│                      │   高带宽连接     │                                    │
│                      └────────┬────────┘                                    │
│                               │                                             │
│  ═══════════════════════════════════════════════════════════════════════   │
│  │                        Shim Tile 层 (L3 接口)                        │   │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐             │   │
│  │  │ Shim 0   │  │ Shim 1   │  │ Shim 2   │  │ Shim 3   │ ...        │   │
│  │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │             │   │
│  │  │ │MM2S  │ │  │ │MM2S  │ │  │ │MM2S  │ │  │ │MM2S  │ │← 内存到流   │   │
│  │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │             │   │
│  │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │             │   │
│  │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │             │   │
│  │  │ │S2MM  │ │  │ │S2MM  │ │  │ │S2MM  │ │  │ │S2MM  │ │← 流到内存   │   │
│  │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │             │   │
│  │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │             │   │
│  │  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘             │   │
│  │       │             │             │             │                   │   │
│  ═══════════════════════════════════════════════════════════════════════   │
│          │             │             │             │                       │
│  ┌───────┴─────────────┴─────────────┴─────────────┴───────────────────┐   │
│  │                    Memory Tile 层 (L2 - 4MB total)                  │   │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐            │   │
│  │  │ Mem Tile │  │ Mem Tile │  │ Mem Tile │  │ Mem Tile │ ...        │   │
│  │  │  512KB   │  │  512KB   │  │  512KB   │  │  512KB   │            │   │
│  │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │  │ ┌──────┐ │            │   │
│  │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │  │ │ DMA  │ │← L2↔L1    │   │
│  │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │  │ └──────┘ │            │   │
│  │  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘            │   │
│  └───────┼─────────────┼─────────────┼─────────────┼───────────────────┘   │
│          │             │             │             │                       │
│  ┌───────┴─────────────┴─────────────┴─────────────┴───────────────────┐   │
│  │                    AIE Compute Tile 层 (32 tiles)                   │   │
│  │                                                                     │   │
│  │   Row 3  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ...         │   │
│  │          │ AIE │══│ AIE │══│ AIE │══│ AIE │══│ AIE │               │   │
│  │          │64KB │  │64KB │  │64KB │  │64KB │  │64KB │← L1 SRAM      │   │
│  │          └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘  └──╫──┘               │   │
│  │   ...       ║        ║        ║        ║        ║                  │   │
│  │                                                                     │   │
│  │   ══ : AXI-Stream (水平数据流)                                      │   │
│  │   ║  : 内存接口 (垂直, 256-bit)                                     │   │
│  │   每个 AIE 可访问相邻 tile 的 L1 SRAM                                │   │
│  │                                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.5 三方数据交互场景：LLM 混合推理

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   LLM 混合推理数据流                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  步骤 1: CPU 准备数据                                                       │
│  ═══════════════════════════════                                            │
│                                                                             │
│  ┌─────────┐     输入 tokens      ┌─────────────────────────┐              │
│  │  CPU    │ ──────────────────► │    统一内存 (共享区)      │              │
│  │         │     tokenized       │    input_ids[]           │              │
│  └─────────┘     embeddings      └─────────────────────────┘              │
│                                             │                               │
│                                             │ 零拷贝 (指针传递)              │
│                                             ▼                               │
│  步骤 2: NPU 执行 Prefill                                                   │
│  ═══════════════════════════════                                            │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                           NPU                                       │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  Shim DMA (MM2S)                                              │ │   │
│  │  │  从统一内存读取: embeddings, weights                           │ │   │
│  │  │  Tiling: 按 L2→L1 大小切分                                     │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │                              │                                      │   │
│  │                              ▼                                      │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  AIE 阵列计算                                                 │ │   │
│  │  │  - Self-Attention (Q, K, V 投影)                              │ │   │
│  │  │  - FFN 前向                                                   │ │   │
│  │  │  - 生成 KV Cache                                              │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │                              │                                      │   │
│  │                              ▼                                      │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  Shim DMA (S2MM)                                              │ │   │
│  │  │  写回统一内存: KV Cache, hidden states                         │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                             │                               │
│                                             │ KV Cache 在内存中              │
│                                             ▼                               │
│  步骤 3: GPU 执行 Decode (迭代)                                             │
│  ═══════════════════════════════════                                        │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                           GPU                                       │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  从统一内存读取 (GPU 可直接读 CPU 区域!)                        │ │   │
│  │  │  - KV Cache (NPU 写入的)                                       │ │   │
│  │  │  - 上一个 token 的 hidden state                                │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │                              │                                      │   │
│  │                              ▼                                      │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │  RDNA 3.5 Compute                                             │ │   │
│  │  │  - Attention with KV Cache (memory-bound)                     │ │   │
│  │  │  - 利用 212 GB/s 带宽                                         │ │   │
│  │  │  - 生成下一个 token                                           │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │                              │                                      │   │
│  │                              ▼                                      │   │
│  │  写入 GPU 专用区: 更新 KV Cache                                    │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                             │                               │
│                                             │ 循环直到 EOS                   │
│                                             ▼                               │
│  步骤 4: CPU 后处理                                                         │
│  ═══════════════════                                                        │
│  ┌─────────┐    读取输出 tokens   ┌─────────────────────────┐              │
│  │  CPU    │ ◄────────────────── │    统一内存              │              │
│  │         │    detokenize       │    output_ids[]          │              │
│  └─────────┘                     └─────────────────────────┘              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.6 数据传输带宽与延迟

| 路径 | 带宽 | 延迟 | 方式 |
|------|------|------|------|
| CPU ↔ DRAM | ~100 GB/s (读) | ~100 ns | 缓存层次 |
| GPU ↔ DRAM | ~212 GB/s | ~150 ns | 直接/MALL |
| NPU ↔ DRAM | 高带宽 (共享) | ~100+ ns | DMA |
| CPU ↔ GPU (共享内存) | 零拷贝 | < 1 μs | 指针 |
| CPU → NPU (命令) | 低带宽 | ~1 μs | PCIe BAR |
| NPU L3 → L2 (DMA) | ~数十 GB/s | ~10 ns | Shim DMA |
| NPU L2 → L1 (DMA) | ~10+ GB/s | ~几 ns | Mem DMA |
| NPU L1 (tile 间) | 256b/cyc | ~1 cyc | 邻居访问 |
| GPU 内部 (SM ↔ L2) | TB/s 级别 | ~100 cyc | 片上网络 |

**关键点：**
1. CPU↔GPU: 统一内存消除了显式拷贝 (传统需要 cudaMemcpy)
2. NPU: 通过 DMA 预取数据到 L2/L1，隐藏 DRAM 延迟
3. GPU: 依赖高带宽，MALL cache 帮助减少 DRAM 访问
4. 三者共享物理内存，但有不同的访问权限和优化路径

### 5.7 与传统离散 GPU 的对比

```
┌─────────────────────────────────────────────────────────────────────────────┐
│              传统系统 vs Strix Halo 统一架构                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  传统系统 (离散 GPU):                                                        │
│  ══════════════════════                                                     │
│                                                                             │
│  ┌─────────┐   PCIe 4.0 x16    ┌─────────────┐                             │
│  │   CPU   │◄═══════════════►│  离散 GPU   │                             │
│  │         │    ~32 GB/s       │   (独立)    │                             │
│  └────┬────┘                   └──────┬──────┘                             │
│       │                               │                                     │
│       ▼                               ▼                                     │
│  ┌─────────┐                   ┌─────────────┐                             │
│  │ 系统内存 │  cudaMemcpy()   │   显存      │                             │
│  │  DDR5   │ ═══════════════► │  HBM/GDDR  │                             │
│  └─────────┘   显式拷贝!       └─────────────┘                             │
│                                                                             │
│  问题:                                                                       │
│  - 每次 GPU 计算前需要 cudaMemcpy (H2D)                                     │
│  - 每次结果需要 cudaMemcpy (D2H)                                            │
│  - PCIe 成为瓶颈 (~32 GB/s << GPU 带宽)                                     │
│  - 显存大小固定，无法扩展                                                    │
│                                                                             │
│  ─────────────────────────────────────────────────────────────────────────  │
│                                                                             │
│  Strix Halo 统一架构:                                                        │
│  ═════════════════════                                                      │
│                                                                             │
│  ┌─────────┐                   ┌─────────────┐                             │
│  │   CPU   │ ◄──── Infinity ───► │    GPU    │                             │
│  │         │      Fabric        │  (片上)    │                             │
│  └────┬────┘     ~1 TB/s        └──────┬──────┘                             │
│       │                               │                                     │
│       │         ┌─────────┐          │                                     │
│       └────────►│   NPU   │◄─────────┘                                     │
│                 └────┬────┘                                                 │
│                      │                                                      │
│                      ▼                                                      │
│               ┌─────────────┐                                               │
│               │  统一内存    │                                               │
│               │  LPDDR5X    │                                               │
│               │  128GB      │                                               │
│               │  256 GB/s   │                                               │
│               └─────────────┘                                               │
│                                                                             │
│  优势:                                                                       │
│  - 零拷贝数据共享 (指针传递)                                                 │
│  - 内存容量灵活分配 (32GB CPU + 96GB GPU, 或其他比例)                        │
│  - Infinity Fabric 带宽远超 PCIe                                            │
│  - NPU 可直接访问同一内存池                                                  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 6. UMA vs 分离式架构分析

### 6.1 为什么要采用 UMA 架构？

#### 核心驱动力：突破内存墙 (Memory Wall)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         大模型推理的内存墙问题                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  问题背景:                                                                   │
│  ═════════                                                                  │
│  - LLM 参数量指数增长 (GPT-4: ~1.8T, Llama 70B: 140GB FP16)                  │
│  - 传统 GPU 显存固定 (RTX 4090: 24GB, A100: 80GB)                            │
│  - 显存不足时需要 CPU offload → PCIe 成为致命瓶颈                             │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    传统架构的困境                                    │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │                                                                     │   │
│  │   Llama-70B 推理 on RTX 4090:                                       │   │
│  │   ───────────────────────────                                       │   │
│  │   模型大小: 140 GB (FP16) / 70 GB (INT8)                            │   │
│  │   显存容量: 24 GB                                                    │   │
│  │   缺口: 140 - 24 = 116 GB 需要 offload                               │   │
│  │                                                                     │   │
│  │   PCIe 4.0 x16 带宽: ~32 GB/s                                       │   │
│  │   每 token 需要加载全部权重: 140 GB                                  │   │
│  │   理论最大吞吐: 32 / 140 ≈ 0.23 tokens/s                             │   │
│  │                                                                     │   │
│  │   结论: 完全不可用!                                                  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    Strix Halo UMA 方案                               │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │                                                                     │   │
│  │   Llama-70B 推理 on Strix Halo (128GB):                             │   │
│  │   ─────────────────────────────────────                             │   │
│  │   统一内存: 128 GB                                                   │   │
│  │   模型大小: 70 GB (INT8) 完全驻留内存!                               │   │
│  │   无需 offload，无 PCIe 瓶颈                                         │   │
│  │                                                                     │   │
│  │   GPU 带宽: 212 GB/s                                                 │   │
│  │   Decode 阶段需要访问: ~70 GB 权重                                   │   │
│  │   理论吞吐: 212 / 70 ≈ 3 tokens/s (INT8)                             │   │
│  │   实测 (Q4 量化): 10-15 tokens/s                                     │   │
│  │                                                                     │   │
│  │   结论: 可用的本地大模型体验!                                         │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 UMA vs 分离式架构详细对比

| 维度 | UMA 架构 (Strix Halo) | 分离式架构 (独立显卡) |
|------|----------------------|---------------------|
| **内存容量** | 128GB 统一池，按需分配 | 固定显存 (24-80GB) |
| **内存带宽** | 212 GB/s (GPU) + 共享 | 1-3 TB/s (HBM/GDDR) |
| **数据传输** | 零拷贝，指针共享 | cudaMemcpy, PCIe 32GB/s |
| **功耗** | ~120W 整机 | 300-700W (GPU alone) |
| **便携性** | 笔记本可用 | 需要台式机/服务器 |
| **成本** | $2000-3000 笔记本 | $10000+ (H100) |
| **峰值算力** | ~15 TFLOPS | 1000+ TFLOPS (FP8) |
| **适用场景** | 边缘推理、本地开发 | 训练、大规模推理 |

### 6.3 各架构适用场景分析

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         架构选择决策树                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                          ┌─────────────┐                                    │
│                          │  你的任务？  │                                    │
│                          └──────┬──────┘                                    │
│                                 │                                           │
│              ┌──────────────────┼──────────────────┐                        │
│              ▼                  ▼                  ▼                        │
│       ┌───────────┐      ┌───────────┐      ┌───────────┐                  │
│       │   训练    │      │  大规模   │      │  本地/    │                  │
│       │   模型    │      │  推理服务 │      │  边缘推理 │                  │
│       └─────┬─────┘      └─────┬─────┘      └─────┬─────┘                  │
│             │                  │                  │                         │
│             ▼                  ▼                  ▼                         │
│       ┌───────────┐      ┌───────────┐      ┌───────────┐                  │
│       │  分离式   │      │  分离式   │      │   UMA     │                  │
│       │  多卡集群 │      │  或混合   │      │  (Strix)  │                  │
│       │  H100/B200│      │  Grace    │      │           │                  │
│       │           │      │  Hopper   │      │           │                  │
│       └───────────┘      └───────────┘      └───────────┘                  │
│                                                                             │
│  ─────────────────────────────────────────────────────────────────────────  │
│                                                                             │
│  详细场景分析:                                                               │
│  ═════════════                                                              │
│                                                                             │
│  1. 模型训练 (Training)                                                     │
│     ─────────────────                                                       │
│     需求: 最大算力 + 超高带宽 + 多卡互联                                     │
│     选择: 分离式架构 (H100/B200 NVLink 集群)                                 │
│     原因:                                                                   │
│     - 训练是 compute-bound，需要 1000+ TFLOPS                               │
│     - 梯度同步需要高带宽 NVLink (900 GB/s)                                   │
│     - UMA 的 15 TFLOPS 完全不够用                                            │
│                                                                             │
│  2. 大规模推理服务 (Cloud Inference)                                        │
│     ───────────────────────────────                                         │
│     需求: 高吞吐量 + 低延迟 + 成本效率                                       │
│     选择: 分离式 (H100) 或 混合 (Grace Hopper)                               │
│     原因:                                                                   │
│     - 并发请求需要高算力                                                    │
│     - HBM 带宽保证低延迟                                                    │
│     - Grace Hopper 模糊了边界 (576GB 统一内存)                               │
│                                                                             │
│  3. 本地开发/测试 (Development)                                             │
│     ─────────────────────────────                                           │
│     需求: 能运行大模型 + 成本合理 + 便携                                     │
│     选择: UMA 架构 (Strix Halo)                                              │
│     原因:                                                                   │
│     - 128GB 内存可加载 70B 模型                                              │
│     - 笔记本形态，随处开发                                                   │
│     - 10 tokens/s 足够迭代                                                   │
│                                                                             │
│  4. 边缘部署 (Edge Deployment)                                              │
│     ────────────────────────────                                            │
│     需求: 低功耗 + 无网络 + 实时响应                                         │
│     选择: UMA 架构 (Strix Halo/类似产品)                                     │
│     原因:                                                                   │
│     - 120W 可用电池                                                         │
│     - 无需云连接                                                            │
│     - NPU 专用 AI 加速                                                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.4 LLM 推理性能对比

| 模型 | 硬件配置 | 内存/显存 | Prefill (tok/s) | Decode (tok/s) |
|------|---------|----------|-----------------|----------------|
| Llama-3.1 8B Q4 | Strix Halo | 128GB UMA | ~2000 | ~30 |
| Llama-3.1 8B Q4 | RTX 4090 | 24GB GDDR | ~5000 | ~100 |
| Llama-3.1 70B Q4 | Strix Halo | 128GB UMA | ~200 | ~10 |
| Llama-3.1 70B Q4 | RTX 4090 | 24GB (offload) | N/A | ~0.5 |
| Llama-3.1 70B Q4 | 2x RTX 4090 | 48GB (勉强) | ~500 | ~15 |
| Llama-3.1 70B Q4 | A100 80GB | 80GB HBM | ~2000 | ~50 |
| Llama-3.1 70B FP16 | H100 80GB | 80GB HBM3 | ~3000 | ~80 |
| Llama-3.1 405B Q4 | 8x H100 | 640GB HBM | ~500 | ~20 |

**关键结论：**
1. **8B 模型**: 分离式 RTX 4090 性能更优 (3-4x)
2. **70B 模型**: Strix Halo 可用，RTX 4090 因 offload 不可用
3. **405B 模型**: 只有多卡集群能运行

### 6.5 架构未来发展趋势

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         架构演进路线图                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  时间轴: 2020 ──────────────────────────────────────────────────────► 2030  │
│                                                                             │
│  分离式架构演进:                                                             │
│  ════════════════                                                           │
│                                                                             │
│  A100 ──► H100 ──► H200 ──► B100/B200 ──► Rubin ──► ?                      │
│  (80GB)   (80GB)   (141GB)   (192GB)     (288GB)                            │
│                       │                      │                              │
│                       ▼                      ▼                              │
│              ┌─────────────────────────────────────────┐                    │
│              │    趋势: HBM 容量持续增长                │                    │
│              │    H200: 4.8 TB/s HBM3e                 │                    │
│              │    B200: 8 TB/s HBM3e                   │                    │
│              │    Rubin: 8-10 TB/s HBM4 预期           │                    │
│              └─────────────────────────────────────────┘                    │
│                                                                             │
│  混合/统一架构演进:                                                          │
│  ══════════════════                                                         │
│                                                                             │
│  Grace Hopper ──► Grace Blackwell ──► Grace Rubin ──► ?                    │
│  (576GB)          (~1TB)              (更大)                                │
│       │                                                                     │
│       ▼                                                                     │
│  ┌─────────────────────────────────────────────────────┐                    │
│  │    趋势: CPU-GPU 融合，NVLink-C2C 直连              │                    │
│  │    Grace Hopper: 900 GB/s CPU-GPU 互联              │                    │
│  │    本质上是"超级 UMA"                                │                    │
│  └─────────────────────────────────────────────────────┘                    │
│                                                                             │
│  边缘 UMA 架构演进:                                                          │
│  ══════════════════                                                         │
│                                                                             │
│  Apple M1 ──► M2 ──► M3 ──► M4 ──► ...                                     │
│  (16GB)      (24GB)  (128GB) (256GB?)                                       │
│                                                                             │
│  Strix Point ──► Strix Halo ──► 下一代 ──► ...                             │
│  (32GB)          (128GB)       (256GB?)                                     │
│       │                                                                     │
│       ▼                                                                     │
│  ┌─────────────────────────────────────────────────────┐                    │
│  │    趋势: 更大内存 + 更高带宽 + 专用 AI 单元         │                    │
│  │    LPDDR5X → LPDDR6 (预期 ~350 GB/s)               │                    │
│  │    NPU 算力持续提升 (XDNA 2 → 3)                   │                    │
│  └─────────────────────────────────────────────────────┘                    │
│                                                                             │
│  新兴互联技术:                                                               │
│  ══════════════                                                             │
│                                                                             │
│  CXL (Compute Express Link):                                                │
│  ─────────────────────────                                                  │
│  ┌─────────────────────────────────────────────────────┐                    │
│  │    CXL 3.0: 允许内存池化                            │                    │
│  │    - 多个 CPU/GPU 共享大容量内存池                  │                    │
│  │    - TB 级别扩展可能                                │                    │
│  │    - 模糊分离式 vs UMA 的界限                       │                    │
│  └─────────────────────────────────────────────────────┘                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.6 结论：分离式架构会消亡吗？

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              最终结论                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                        分离式架构不会消亡                                    │
│                        ═══════════════════                                  │
│                                                                             │
│  但会发生深刻变革:                                                           │
│                                                                             │
│  1. 融合趋势不可逆                                                           │
│     ─────────────                                                           │
│     - NVIDIA Grace Hopper 模式将成为数据中心新标准                           │
│     - CPU-GPU 紧密耦合，内存共享或直连                                       │
│     - "分离式"变为"封装分离，逻辑统一"                                       │
│                                                                             │
│  2. 场景分化加剧                                                             │
│     ─────────────                                                           │
│     ┌───────────────────┐  ┌───────────────────┐  ┌───────────────────┐    │
│     │    边缘/本地      │  │    企业推理       │  │    训练/研究      │    │
│     │    ───────────    │  │    ───────────    │  │    ───────────    │    │
│     │    纯 UMA 架构    │  │    混合架构       │  │    分离式集群     │    │
│     │    Strix Halo    │  │    Grace Hopper   │  │    H100/B200     │    │
│     │    Apple M系列   │  │    AMD MI300A     │  │    多卡 NVLink   │    │
│     └───────────────────┘  └───────────────────┘  └───────────────────┘    │
│                                                                             │
│  3. 内存技术决定上限                                                         │
│     ─────────────────                                                       │
│     - HBM: 极致带宽，容量有限 → 训练/高性能推理                              │
│     - LPDDR: 容量友好，带宽中等 → 边缘推理                                   │
│     - CXL: 容量无限扩展，延迟较高 → 大模型服务                               │
│                                                                             │
│  4. 对推理框架开发者的建议                                                   │
│     ─────────────────────                                                   │
│     - 必须支持多种内存模型 (统一 vs 分离)                                    │
│     - 充分利用零拷贝能力 (UMA 场景)                                          │
│     - 设计灵活的 offload 策略                                                │
│     - 关注 CXL 等新互联标准                                                  │
│     - NPU/专用加速器将成为标配                                               │
│                                                                             │
│  ═══════════════════════════════════════════════════════════════════════    │
│                                                                             │
│                  未来是 "异构融合"，而非 "架构消亡"                           │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 7. 信息来源与参考资料

### 7.1 AMD 官方文档

| 来源 | 描述 | URL |
|------|------|-----|
| AMD Ryzen AI Max 产品页 | 官方规格与产品定位 | https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series.html |
| AMD ROCm 文档 | GPU 编程框架官方文档 | https://rocm.docs.amd.com/ |
| AMD XDNA 架构文档 | NPU 架构技术白皮书 | https://www.amd.com/en/technologies/xdna.html |
| Vitis AI 用户指南 | NPU 开发官方指南 | https://docs.amd.com/r/en-US/ug1414-vitis-ai |
| AMD Ryzen AI Software | NPU 驱动与运行时 | https://ryzenai.docs.amd.com/ |

### 7.2 开源项目与代码仓库

| 项目 | 描述 | URL |
|------|------|-----|
| MLIR-AIE | AMD AIE 开源编译器基础设施 | https://github.com/Xilinx/mlir-aie |
| IRON (Intermediate Representation) | 高级 AIE 编程抽象 | https://github.com/Xilinx/mlir-aie/tree/main/python |
| Peano (LLVM-AIE) | AIE 后端编译器 | https://github.com/Xilinx/llvm-aie |
| ROCm | AMD GPU 开源计算平台 | https://github.com/ROCm |
| llama.cpp | LLM 推理框架 (HIP 支持) | https://github.com/ggerganov/llama.cpp |
| ONNX Runtime | 跨平台推理 (DML/ROCm) | https://github.com/microsoft/onnxruntime |

### 7.3 技术博客与深度分析

| 来源 | 标题/主题 | URL |
|------|----------|-----|
| AnandTech | AMD Strix Halo 深度测评 | https://www.anandtech.com/ |
| Tom's Hardware | Ryzen AI Max 发布报道 | https://www.tomshardware.com/ |
| ServeTheHome | AMD AI 架构分析 | https://www.servethehome.com/ |
| Chips and Cheese | RDNA 3.5 / XDNA 2 微架构分析 | https://chipsandcheese.com/ |
| Phoronix | Linux ROCm/AMDGPU 支持 | https://www.phoronix.com/ |

### 7.4 学术论文与技术规范

| 来源 | 描述 |
|------|------|
| AMD Versal AI Engine (AIE) Architecture Manual | AIE Tile 微架构详细规范 |
| MLIR: A Compiler Infrastructure for the End of Moore's Law | MLIR 编译器框架论文 |
| Spatial Dataflow Architectures Survey | 空间数据流架构综述 |
| CXL Consortium Specifications | CXL 互联协议规范 |

### 7.5 行业新闻与发布会

| 事件 | 日期 | 内容 |
|------|------|------|
| CES 2025 | 2025年1月 | AMD 发布 Ryzen AI Max+ 395 (Strix Halo) |
| CES 2026 | 2026年1月 | AMD 发布 Ryzen AI Max+ 392/388, Ryzen AI 400 系列 |
| AMD Advancing AI Event | 2024年 | XDNA 2 架构详解 |
| NVIDIA GTC 2024 | 2024年3月 | Grace Hopper / Blackwell 发布 |

### 7.6 开发者社区与论坛

| 平台 | 描述 | URL |
|------|------|-----|
| AMD ROCm GitHub Issues | ROCm 问题追踪与讨论 | https://github.com/ROCm/ROCm/issues |
| r/Amd (Reddit) | AMD 用户社区 | https://www.reddit.com/r/Amd/ |
| AMD Community Forums | 官方开发者论坛 | https://community.amd.com/ |
| Level1Techs Forum | 高级技术讨论 | https://forum.level1techs.com/ |

### 7.7 工具与测试基准

| 工具/基准 | 用途 |
|----------|------|
| rocm-smi | AMD GPU 监控与管理 |
| rocprofiler | GPU 性能分析 |
| xrt (Xilinx Runtime) | NPU 运行时管理 |
| Geekbench AI | 跨平台 AI 性能测试 |
| llama-bench | LLM 推理性能测试 |

---

## 8. 附录

### 8.1 术语表

| 术语 | 全称 | 描述 |
|------|------|------|
| UMA | Unified Memory Architecture | 统一内存架构 |
| NPU | Neural Processing Unit | 神经网络处理单元 |
| iGPU | Integrated Graphics Processing Unit | 集成显卡 |
| AIE | AI Engine | AMD 的 AI 计算单元 |
| XDNA | (AMD NPU 架构名称) | AMD NPU 体系结构 |
| RDNA | Radeon DNA | AMD GPU 架构 |
| ROCm | Radeon Open Compute | AMD GPU 计算平台 |
| HIP | Heterogeneous-compute Interface for Portability | AMD 异构计算接口 |
| MLIR | Multi-Level Intermediate Representation | 多层中间表示编译器基础设施 |
| VLIW | Very Long Instruction Word | 超长指令字 |
| SIMT | Single Instruction Multiple Threads | 单指令多线程 |
| SIMD | Single Instruction Multiple Data | 单指令多数据 |
| DMA | Direct Memory Access | 直接内存访问 |
| MALL | Memory Access Last Level (Infinity Cache) | 末级缓存 |
| CXL | Compute Express Link | 计算快捷链接互联协议 |
| HBM | High Bandwidth Memory | 高带宽内存 |
| LPDDR | Low Power DDR | 低功耗 DDR 内存 |
| TOPS | Tera Operations Per Second | 每秒万亿次操作 |
| TFLOPS | Tera Floating Point Operations Per Second | 每秒万亿次浮点运算 |

### 8.2 性能计算公式

**LLM Decode 阶段吞吐量估算：**
```
Tokens/s ≈ Memory_Bandwidth (GB/s) / Model_Size (GB)
```

**NPU 算力计算：**
```
TOPS = Tiles × MACs_per_tile × 2 × Frequency (GHz)
     = 32 × 128 × 2 × 1.6 GHz ≈ 13 TOPS (INT8 单引擎)
     实际有多引擎和额外优化，达到 50 TOPS
```

**GPU 峰值算力：**
```
TFLOPS = CUs × Shader_per_CU × 2 (FMA) × Frequency (GHz)
       = 40 × 64 × 2 × 2.9 ≈ 14.8 TFLOPS (FP32)
```

---

*报告生成时间: 2026年1月7日*
*调研对象: AMD Ryzen AI Max 系列处理器架构*
*目标读者: 推理框架开发者*

